knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
cache = FALSE,
warning = FALSE,
fig.align = 'center',
dpi = 300)
# Installing and loading  packages
packages <- function(x){
not_installed <- x[!x %in% installed.packages()[, "Package"]]
if(length(not_installed) > 0)
install.packages(not_installed, dependencies = TRUE)
invisible(lapply(x, require, character.only = TRUE))
}
packages(c("magrittr", "dplyr", "tidyverse", "GGally", "ggpubr", "corrplot", "FactoMineR", "factoextra", "randomForest"))
# Installing and loading  packages
packages <- function(x){
not_installed <- x[!x %in% installed.packages()[, "Package"]]
if(length(not_installed) > 0)
install.packages(not_installed, dependencies = TRUE)
invisible(lapply(x, require, character.only = TRUE))
}
packages(c("magrittr", "dplyr", "tidyverse", "GGally", "ggpubr", "corrplot", "FactoMineR", "factoextra", "randomForest"))
# Setting the working directory to the folder containing the currently open file in RStudio
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Loading data
data <- read.csv2("input_file.csv", header = TRUE, dec = ",")
# Data sorting
SortedData <- data[order(data[, ncol(data)]), ]
# The most extreme values should be included in the training set. The number of rows with the lowest and highest values to be included in the training set:
nexv = 3
ExRows <- rbind(SortedData[1:nexv, ], SortedData[(nrow(SortedData)-nexv+1):nrow(SortedData), ])
DataSplit <- SortedData[-c(1:nexv, (nrow(SortedData)-nexv+1):nrow(SortedData)), ]
# Training and validation sets
ValidationSet <- data.frame()
TrainingSet <- data.frame()
for (i in seq_len(nrow(DataSplit))) {
# The data split ratio is 2:1, where every third element is placed in the validation set
if (i %% 3 == 1) {
ValidationSet <- rbind(ValidationSet, DataSplit[i, ])
} else {
TrainingSet <- rbind(TrainingSet, DataSplit[i, ])
}
}
TrainingSet <- rbind(ExRows, TrainingSet)
TrainingSet$Set <- 'T'
ValidationSet$Set <- 'V'
# Responces vectors
RespTrain <- as.vector(TrainingSet[, ncol(TrainingSet) - 1])
RespVal <- as.vector(ValidationSet[, ncol(ValidationSet) - 1])
# Matrix with descriptors
DescT <- as.matrix(TrainingSet[, 2:(ncol(TrainingSet) - 2)])
DescV <- as.matrix(ValidationSet[, 2:(ncol(ValidationSet) - 2)])
# Name of columns
ChemNameT <- TrainingSet[,1]
ChemNameV <- ValidationSet[,1]
# Autoscaling data
scaling <- function(x, sc_data){
average <- mean(sc_data)
stdev <- sd(sc_data)
if (stdev == 0) {
return(rep(0, length(x)))
}
autoscaled_x <- (x-average)/stdev
autoscaled_x
}
AutoscDescT <- as.data.frame(matrix(NA, nrow = nrow(DescT), ncol = ncol(DescT)))
AutoscDescV <- as.data.frame(matrix(NA, nrow = nrow(DescV), ncol = ncol(DescV)))
for (i in 1:ncol(DescT)) {
AutoscDescT[, i] <- scaling(DescT[, i], DescT[, i])
}
for (i in 1:ncol(DescV)) {
AutoscDescV[, i] <- scaling(DescV[, i], DescT[, i])
}
DescNames <- colnames(DescT)
AutoscDescNames <- paste0("Autoscaled_", DescNames)
# Summary table
Summary <- data.frame(rbind(
setNames(cbind(ChemNameT, DescT, AutoscDescT, RespTrain, TrainingSet$Set),
c("ChemName", DescNames, AutoscDescNames, "Experimental", "Set")),
setNames(cbind(ChemNameV, DescV, AutoscDescV, RespVal, ValidationSet$Set),
c("ChemName", DescNames, AutoscDescNames, "Experimental", "Set"))))
rownames(Summary) <- NULL
print(Summary)
# Metrics
R2Q2 <- function(experimental, predicted) {
return(1 - sum((experimental - predicted)^2, na.rm = TRUE) / sum((experimental - mean(experimental, na.rm = TRUE))^2, na.rm = TRUE))
}
# Grid parameters
set.seed(8)
SampizePerc <- floor(nrow(AutoscDescT) * c(0.5, 0.7, 0.9, 1))
grid <- expand.grid(ntree = c(500, 750, 1000),
mtry = seq(2, 4, by = 1),
nodsize = c(1, 5, 10, 20),
sampsize = SampizePerc,
maxnodes = seq(5, 25, by = 5))
# Table for resuts
results <- data.frame(ntree = numeric(), mtry = numeric(), nodsize = numeric(), sampsize = numeric(), maxnodes = numeric(), Q2 = numeric(), R2 = numeric())
# Grid search
for (i in 1:nrow(grid)) {
params <- grid[i,]
set.seed(8)
model <- randomForest(x = AutoscDescT, RespTrain,
ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
replace = TRUE,
importance = TRUE,
do.trace = FALSE)
RespTrainPred <- predict(model, newdata = AutoscDescT)
RespValPred <- predict(model, newdata = AutoscDescV)
R2 <- R2Q2(RespTrain, RespTrainPred)
Q2 <- R2Q2(RespVal, RespValPred)
results <- rbind(results, data.frame(ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
Q2 = Q2,
R2 = R2))
}
print(results)
# Metrics
R2Q2 <- function(experimental, predicted) {
return(1 - sum((experimental - predicted)^2, na.rm = TRUE) / sum((experimental - mean(experimental, na.rm = TRUE))^2, na.rm = TRUE))
}
# Grid parameters
set.seed(8)
SampizePerc <- floor(nrow(AutoscDescT) * c(0.5, 0.7, 0.9, 1))
grid <- expand.grid(ntree = c(500, 750, 1000),
mtry = seq(2, 4, by = 1),
nodsize = c(1, 5, 10, 20),
sampsize = SampizePerc,
maxnodes = seq(5, 25, by = 5))
# Table for resuts
results <- data.frame(ntree = numeric(), mtry = numeric(), nodsize = numeric(), sampsize = numeric(), maxnodes = numeric(), Q2 = numeric(), R2 = numeric())
# Grid search
for (i in 1:nrow(grid)) {
params <- grid[i,]
set.seed(8)
model <- randomForest(x = AutoscDescT, RespTrain,
ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
replace = TRUE,
importance = TRUE,
do.trace = FALSE)
RespTrainPred <- predict(model, newdata = AutoscDescT)
RespValPred <- predict(model, newdata = AutoscDescV)
R2 <- R2Q2(RespTrain, RespTrainPred)
Q2 <- R2Q2(RespVal, RespValPred)
if (Q2 > 0.9) {
results <- rbind(results, data.frame(ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
Q2 = Q2,
R2 = R2))
}
}
print(results)
# Metrics
R2Q2 <- function(experimental, predicted) {
return(1 - sum((experimental - predicted)^2, na.rm = TRUE) / sum((experimental - mean(experimental, na.rm = TRUE))^2, na.rm = TRUE))
}
# Grid parameters
set.seed(8)
SampizePerc <- floor(nrow(AutoscDescT) * c(0.5, 0.7, 0.9, 1))
grid <- expand.grid(ntree = c(500, 750, 1000),
mtry = seq(2, 4, by = 1),
nodsize = c(1, 5, 10, 20),
sampsize = SampizePerc,
maxnodes = seq(5, 25, by = 5))
# Table for resuts
results <- data.frame(ntree = numeric(), mtry = numeric(), nodsize = numeric(), sampsize = numeric(), maxnodes = numeric(), Q2 = numeric(), R2 = numeric())
# Grid search
for (i in 1:nrow(grid)) {
params <- grid[i,]
set.seed(8)
model <- randomForest(x = AutoscDescT, RespTrain,
ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
replace = TRUE,
importance = TRUE,
do.trace = FALSE)
RespTrainPred <- predict(model, newdata = AutoscDescT)
RespValPred <- predict(model, newdata = AutoscDescV)
R2 <- R2Q2(RespTrain, RespTrainPred)
Q2 <- R2Q2(RespVal, RespValPred)
if (Q2 > 0.85) {
results <- rbind(results, data.frame(ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
Q2 = Q2,
R2 = R2))
}
}
print(results)
# Metrics
R2Q2 <- function(experimental, predicted) {
return(1 - sum((experimental - predicted)^2, na.rm = TRUE) / sum((experimental - mean(experimental, na.rm = TRUE))^2, na.rm = TRUE))
}
# Grid parameters
set.seed(8)
SampizePerc <- floor(nrow(AutoscDescT) * c(0.5, 0.7, 0.9, 1))
grid <- expand.grid(ntree = c(500, 750, 1000),
mtry = seq(2, 4, by = 1),
nodsize = c(1, 5, 10, 20),
sampsize = SampizePerc,
maxnodes = seq(5, 25, by = 5))
# Table for resuts
results <- data.frame(ntree = numeric(), mtry = numeric(), nodsize = numeric(), sampsize = numeric(), maxnodes = numeric(), Q2 = numeric(), R2 = numeric())
# Grid search
for (i in 1:nrow(grid)) {
params <- grid[i,]
set.seed(8)
model <- randomForest(x = AutoscDescT, RespTrain,
ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
replace = TRUE,
importance = TRUE,
do.trace = FALSE)
RespTrainPred <- predict(model, newdata = AutoscDescT)
RespValPred <- predict(model, newdata = AutoscDescV)
R2 <- R2Q2(RespTrain, RespTrainPred)
Q2 <- R2Q2(RespVal, RespValPred)
# First selection
if (Q2 > 0.85) {
results <- rbind(results, data.frame(ntree = params$ntree,
mtry = params$mtry,
nodsize = params$nodsize,
sampsize = params$sampsize,
maxnodes = params$maxnodes,
Q2 = Q2,
R2 = R2))
}
}
# The secon selection
ResultSort <- results[order(-results$Q2), ]
print(head(ResultSort))
