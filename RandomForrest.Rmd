---
title: "Machine learning – Random Forrests + Data Analysis"
author: "Michalina Miszczak"
date: "2025-03-03"
output: 
  html_document:  
    self_contained: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      cache = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      dpi = 300)
```


```{r packages, echo=FALSE}
# Installing and loading  packages
packages <- function(x){
  not_installed <- x[!x %in% installed.packages()[, "Package"]]
  if(length(not_installed) > 0) 
    install.packages(not_installed, dependencies = TRUE)
  invisible(lapply(x, require, character.only = TRUE))
}

packages(c("magrittr", "dplyr", "tidyverse", "GGally", "ggpubr", "corrplot", "FactoMineR", "factoextra", "randomForest"))
```

### Setting the working directory and importing data

```{r data import}
# Setting the working directory to the folder containing the currently open file in RStudio
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Loading data
data <- read.csv2("input_file.csv", header = TRUE, dec = ",")
```


### Data preparing

```{r splitting, autoscaling}
# Data sorting
SortedData <- data[order(data[, ncol(data)]), ]

# The most extreme values should be included in the training set. The number of rows with the lowest and highest values to be included in the training set: 
nexv = 3

ExRows <- rbind(SortedData[1:nexv, ], SortedData[(nrow(SortedData)-nexv+1):nrow(SortedData), ])
DataSplit <- SortedData[-c(1:nexv, (nrow(SortedData)-nexv+1):nrow(SortedData)), ]

# Training and validation sets 
ValidationSet <- data.frame()  
TrainingSet <- data.frame()       

for (i in seq_len(nrow(DataSplit))) {
  # The data split ratio is 2:1, where every third element is placed in the validation set
  if (i %% 3 == 1) {
    ValidationSet <- rbind(ValidationSet, DataSplit[i, ])
  } else {
    TrainingSet <- rbind(TrainingSet, DataSplit[i, ])
  }
}

TrainingSet <- rbind(ExRows, TrainingSet)

TrainingSet$Set <- 'T'
ValidationSet$Set <- 'V'

# Responces vectors
RespTrain <- as.vector(TrainingSet[, ncol(TrainingSet) - 1])
RespVal <- as.vector(ValidationSet[, ncol(ValidationSet) - 1])

# Matrix with descriptors
DescT <- as.matrix(TrainingSet[, 2:(ncol(TrainingSet) - 2)])
DescV <- as.matrix(ValidationSet[, 2:(ncol(ValidationSet) - 2)])

# Name of columns
ChemNameT <- TrainingSet[,1]
ChemNameV <- ValidationSet[,1]

# Autoscaling data
scaling <- function(x, sc_data){
  average <- mean(sc_data)
  stdev <- sd(sc_data)
  if (stdev == 0) {
    return(rep(0, length(x)))  
  }
  autoscaled_x <- (x-average)/stdev
  autoscaled_x
}

AutoscDescT <- as.data.frame(matrix(NA, nrow = nrow(DescT), ncol = ncol(DescT)))
AutoscDescV <- as.data.frame(matrix(NA, nrow = nrow(DescV), ncol = ncol(DescV)))


for (i in 1:ncol(DescT)) {
  AutoscDescT[, i] <- scaling(DescT[, i], DescT[, i])
}

for (i in 1:ncol(DescV)) {
  AutoscDescV[, i] <- scaling(DescV[, i], DescT[, i])
}

DescNames <- colnames(DescT)
AutoscDescNames <- paste0("Autoscaled_", DescNames) 

# Summary table
Summary <- data.frame(rbind(
  setNames(cbind(ChemNameT, DescT, AutoscDescT, RespTrain, TrainingSet$Set), 
           c("ChemName", DescNames, AutoscDescNames, "Experimental", "Set")), 
  setNames(cbind(ChemNameV, DescV, AutoscDescV, RespVal, ValidationSet$Set), 
           c("ChemName", DescNames, AutoscDescNames, "Experimental", "Set"))))

rownames(Summary) <- NULL

print(head(Summary))
print(tail(Summary))

```

### Heatmap

The heatmap plot displays the correlation levels between the independent variables. Correlation coefficients are determined using Pearson's test.

```{r heatmap for independent variables}
# Save Heatmap to PNG
png("docs/figures/HeatMap.png", width = 1500, height = 1500, units = "px", res = 300)

# Computing the correlation matrix

CorrelationMatrix <- cor(data[, 2:(ncol(data) - 1)], use = "complete.obs")

# Color palette for the plot
col <- colorRampPalette(c("#6e7222","#b8bf3a", "#c6cb61", "#dbdf9c", "#b3b0e5", "#5c57ac", "#2e2988", "#292479"))

# Heatmap
corrplot(CorrelationMatrix, 
          method = "color", 
          col = col(100), 
          tl.col = "black", 
          tl.srt = 45, 
          addCoef.col = "black", 
          number.cex=0.8,
          tl.cex = 0.9,
          cl.cex = 0.9)

invisible(dev.off())
```

![](docs/figures/HeatMap.png){width=60%}

### Boxplots 

The distribution of the dependent variable is shown across different doses and exposure durations to the nanomaterial. The boxplot highlights the toxicity values, with the median indicated by the thick line within the box. The box boundaries represent the first and third quartiles of the data, while the "whiskers" extend to 1.5 times the interquartile range (IQR) beyond the quartiles. Points beyond this range are identified as outliers.

```{r boxplot for dependent variables}
#Save Boxplot to PNG
png("docs/figures/Boxplot.png", width = 2400, height = 1440, units = "px", res = 300)

# Arranging two plots horizontally in a single graphic
par(mfrow = c(1,2))

# Boxplots
boxplot(TDNA~ Dose, 
        data = data,
        col = "#09938F", 
        xlab = "Dose", 
        ylab = "%TDNA", 
        main = "Distribution of %TDNA values",
        cex.axis = 0.5, 
        cex.lab = 1,    
        cex.main = 1.2)
boxplot(TDNA~ Day, 
        data = data,
        col = "#8f0993", 
        xlab = "Day", 
        ylab = "%TDNA", 
        main = "Distribution of %TDNA values",
        cex.axis = 0.5, 
        cex.lab = 1,    
        cex.main = 1.2)

invisible(dev.off())
```

![](docs/figures/Boxplot.png)

### PCA analysis 

```{r PCA}
# Selecting data for PCA
DataPCA <- data[, -c(1, ncol(data))]
# PCA
ResultsPCA <-  PCA(DataPCA, scale.unit = TRUE, ncp = 5, graph = FALSE)

EigenValues <- ResultsPCA$eig 

print(EigenValues)

# Setting the maximum value on the Y-axis
MaxYEV <- max(EigenValues[, "percentage of variance"]) + 5 
# Save Scree plot to PNG
png("docs/figures/EigenValues.png", width = 2400, height = 1900, units = "px", res = 300)
# Scree plot
fviz_eig(ResultsPCA, 
         addlabels = TRUE, 
         main = "Scree plot",
         col = "#09938F",              
         barfill = "#09938F",   
         border = "black",
         ylim = c(0, MaxYEV)) +
  theme(
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(), 
    panel.grid.minor.x = element_blank(),
    panel.background = element_rect(fill = "white", color = NA), 
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title = element_text(size = 15))
invisible(dev.off())

# Save Contributions plot to PNG
png("docs/figures/Correlation_circle.png", width = 2400, height = 1440, units = "px", res = 300)
# Contributions plot
fviz_pca_var(ResultsPCA, 
             col.var = "contrib",
             gradient.cols = c("#9ab7bf", "#366f7f", "#033c4c")) +
  ggtitle("PCA Variable Contributions") +
  theme(
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.background = element_rect(fill = "white", color = NA), 
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title = element_text(size = 15),
    legend.title = element_text(size = 13),
    legend.text = element_text(size = 11)) +
  labs(color = "Contribution") 
invisible(dev.off())

# Save Biplot to PNG
png("docs/figures/Biplot.png", width = 2400, height = 1900, units = "px", res = 300)
TDNA_PCA <- as.numeric(data$TDNA)
Day_PCA <- as.factor(data$Day)
# Biplot
fviz_pca_biplot(ResultsPCA, 
                # Endpoits
                geom.ind = "point",
                fill.ind = Day_PCA, # color the points based on the day number
                col.ind = "black",
                pointshape = 21, 
                pointsize = TDNA_PCA, # point size depends on toxicity value
                palette = "Dark2",
                repel = TRUE,
                addEllipses = TRUE,
                # Variables 
                col.var = "contrib",
                gradient.cols = c("#9ab7bf", "#366f7f", "#033c4c"),
                
                legend.title = list(fill = "Day", color = "Contribution of variables", size = "Toxicity value")) + 
  labs(title = "PCA", x = "PC1 (41.7%)", y = "PC2 (27.6%)") + 
  theme_bw() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title = element_text(size = 15),
    legend.title = element_text(size = 13),
    legend.text = element_text(size = 11)) 
invisible(dev.off())
```

### Scree plot

The Scree plot displays the eigenvalues for each principal component in PCA, indicating how much variance in the data is explained by each component. The plot helps identify which components have the most significant impact on the data, allowing for the selection of the number of components for further analysis.

![](docs/figures/EigenValues.png){width=70%}

### PCA Variable Contributions

The correlation between a variable and a principal component (PC) is used as the coordinates of the variable on the PC. The contribution represents the proportion of a variable's contribution to a given principal component, expressed as a percentage. 

* Positively correlated variables are grouped together.

* Negatively correlated variables are positioned on opposite sides of the plot origin (opposed quadrants).

Variables that are correlated with PC1 and PC2 are the most important in explaining the variability in the data set.

Information adapted from the detailed study of Principal Component Analysis available at: https://f0nzie.github.io/machine_learning_compilation/detailed-study-of-principal-component-analysis.html

![](docs/figures/Correlation_circle.png)

* Dose: A weak negative contribution to PC1 and a moderate positive contribution to PC2.

* Day: A weak positive contribution to PC1 and a large positive contribution to PC2.

* Aspect ratio: A large positive contribution to PC1 and a weak positive contribution to PC2.

* BET_SSA: A large positive contribution to PC1 and a weak positive contribution to PC2.

* Aspect ratio and BET_SSA are strongly correlated with each other.


### PCA Biplot 

A biplot simultaneously presents the distribution of observations and the contribution of variables. Four key pieces of information can be extracted from it:

1. Distribution of observations: The distance between points indicates the similarity between observations—observations that are closer together are more similar with respect to the variables.

2. Contribution of variables: The direction of the vectors indicates the direction in which the variables have the greatest influence on the principal components, while the length of the vector reflects the strength of this influence. The longer the vector, the stronger the contribution of the variable to the respective component.

3. Relationships between variables: Variables represented by vectors in the same direction are positively correlated, whereas those in opposite directions exhibit negative correlation. Variables that are orthogonal to each other are independent (uncorrelated).

4. Interactions between observations and variables: It is also possible to observe how individual variables influence the positioning of observations in the principal component space. Observations that are close to a given variable’s vector have a high value for that variable.


![](docs/figures/Biplot.png)

### Results 

```{r RF Grid}
# Metrics 
R2Q2 <- function(experimental, predicted) {
  return(1 - sum((experimental - predicted)^2, na.rm = TRUE) / sum((experimental - mean(experimental, na.rm = TRUE))^2, na.rm = TRUE))
}
RMSE <- function(experimental, predicted) {
  return(sqrt(mean((experimental - predicted)^2, na.rm = TRUE)))
}

# Grid parameters 
set.seed(8)

SampizePerc <- floor(nrow(AutoscDescT) * c(0.5, 0.7, 0.9, 1)) 

grid <- expand.grid(ntree = c(500, 750, 1000),
                    mtry = seq(2, 4, by = 1),
                    nodesize = c(1, 5, 10, 20),
                    sampsize = SampizePerc, 
                    maxnodes = seq(5, 25, by = 5))

# Table for resuts
results <- data.frame(ntree = numeric(), mtry = numeric(), nodesize = numeric(), sampsize = numeric(), maxnodes = numeric(), Q2 = numeric(), RMSEext = numeric(), R2 = numeric(), RMSEext = numeric())

# Grid search 
for (i in 1:nrow(grid)) {
  params <- grid[i,]
    set.seed(8)
    model <- randomForest(x = AutoscDescT, RespTrain, 
                          ntree = params$ntree, 
                          mtry = params$mtry, 
                          nodesize = params$nodesize, 
                          sampsize = params$sampsize, 
                          maxnodes = params$maxnodes, 
                          replace = TRUE, 
                          importance = TRUE, 
                          do.trace = FALSE)  
    
    RespTrainPred <- predict(model, newdata = AutoscDescT)
    RespValPred <- predict(model, newdata = AutoscDescV)
  
    R2 <- R2Q2(RespTrain, RespTrainPred)
    RMSEc <- RMSE(RespTrain, RespTrainPred)
    Q2 <- R2Q2(RespVal, RespValPred)
    RMSEext <- RMSE(RespVal, RespValPred)
  
  # First selection 
  if (Q2 > 0.85) {
  results <- rbind(results, data.frame(ntree = params$ntree, 
                                       mtry = params$mtry, 
                                       nodesize = params$nodesize, 
                                       sampsize = params$sampsize, 
                                       maxnodes = params$maxnodes, 
                                       Q2 = Q2, 
                                       RMSEext = RMSEext, 
                                       R2 = R2,
                                       RMSEc = RMSEc))
  }
}

# The secon selection
ResultSort <- results[order(-results$Q2), ]
BestRes <- head(ResultSort)

print(BestRes)
```

The primary evaluation of a model relies on the R² and Q² parameters. R² measures how well the data fit the model, while Q² assesses its predictive power. A key threshold for both is 0.7—values above this indicate good data fit and strong predictive performance. Additionally, the difference between R² and Q² matters; if it exceeds 0.3, it may signal overfitting. For example, with Q² = 0.89 and R² = 0.94, the model's performance is considered satisfactory. The RMSEc (Root Mean Squared Error of calibration) and RMSEext (Root Mean Squared Error of validation) values should be as low as possible and close to each other.

### Leave-One-Out Cross-Validation 

The Leave-One-Out Cross-Validation (LOO CV) method is particularly useful for small to medium-sized datasets, as it can be computationally intensive. The method works by sequentially excluding one data point from the training set, recalibrating the model, and then making a prediction for the excluded point. The model's statistics, such as Qcv and RMSEext, follow the same principles as the calibration and external validation statistics described earlier. These metrics help determine whether the model is stable and robust against the removal of individual data points.

```{r crossvalidation}
#Table for results
resultscv <- data.frame(ntree = numeric(), mtry = numeric(), nodesize = numeric(), sampsize = numeric(), maxnodes = numeric(), Q2cv = numeric(), RMSEcv = numeric())

# Loop for parameters
for (i in 1:nrow(BestRes)) {
  HypParm <- BestRes[i, ]
  
  TrainPredLoo <- numeric(length(RespTrain))
  # Loop for crossvalidation
  for (j in 1:length(RespTrain)) {
    TrainIndicates <- setdiff(1:length(RespTrain), j)
    TrainSetLoo <- AutoscDescT[TrainIndicates, ]
    RespTrainLoo <- RespTrain[TrainIndicates]  
    ValSetLoo <- AutoscDescT[j, , drop = FALSE]
    RespValLoo <- RespTrain[j]
    
    set.seed(8)
    # In the training set, there is one less element.
    sampsizevalue <- HypParm$sampsize - 1
    
    model <- randomForest(x = TrainSetLoo, y = RespTrainLoo, 
                          ntree = HypParm$ntree, 
                          mtry = HypParm$mtry, 
                          nodesize = HypParm$nodesize, 
                          sampsize = sampsizevalue, 
                          maxnodes = HypParm$maxnodes, 
                          replace = TRUE, 
                          importance = TRUE, 
                          do.trace = FALSE)  
    
    PredLoo <- predict(model, newdata = ValSetLoo)
    
    TrainPredLoo[j] <- PredLoo
  }
  Q2cv <- R2Q2(RespTrain, TrainPredLoo)
  RMSEcv <- RMSE(RespTrain, TrainPredLoo)

  resultscv <- rbind(resultscv, data.frame(ntree = HypParm$ntree, 
                                       mtry = HypParm$mtry, 
                                       nodesize = HypParm$nodesize, 
                                       sampsize = HypParm$sampsize, 
                                       maxnodes = HypParm$maxnodes, 
                                       Q2cv = Q2cv, 
                                       RMSEcv = RMSEcv))
}

ResultsAll<- cbind(resultscv, Q2ext = BestRes$Q2, RMSEext = BestRes$RMSEext, R2 = BestRes$R2, RMSEc = BestRes$RMSEc)
print(ResultsAll)
```

### The best model

The models obtained from the above calculations are very similar to each other, so the model with the highest values of R² and Q² was selected.

```{r Summary}
# Function for MAE calculation
MAE <- function(experimental, predicted) {
  mean(abs(experimental - predicted), na.rm = TRUE)
}

# Training
set.seed(8)
FinalModel <- randomForest(x = AutoscDescT, y = RespTrain, 
                           ntree = HypParm$ntree, 
                           mtry = HypParm$mtry, 
                           nodesize = HypParm$nodesize, 
                           sampsize = sampsizevalue, 
                           maxnodes = HypParm$maxnodes, 
                           replace = TRUE, 
                           importance = TRUE, 
                           do.trace = FALSE)  
    
RespTrainPred <- predict(FinalModel, newdata = AutoscDescT)
RespValPred <- predict(FinalModel, newdata = AutoscDescV)

ResidualsTrain <- RespTrain - RespTrainPred
ResidualsVal <- RespVal - RespValPred

R2 <- ResultsAll$R2[1]
RMSEc <- ResultsAll$RMSEc[1]
MAEt <- MAE(RespTrain, RespTrainPred)
Q2ext <- ResultsAll$Q2ext[1]
RMSEext <- ResultsAll$RMSEext[1]
Q2cv <- ResultsAll$Q2cv[1]
RMSEcv <- ResultsAll$RMSEcv[1]

SummaryModel <- cbind(Summary, PredictedTox = c(RespTrainPred, RespValPred), Residuals = c(ResidualsTrain, ResidualsVal))
print(head(SummaryModel))
print(tail(SummaryModel))
print(paste("Results of model: R2 = ", round(R2, 2), "RMSEc = ", round(RMSEc, 2), "Q2ext = ", round(Q2ext, 2), "RMSEext = ", round(RMSEext, 2), "Q2cv = ", round(Q2cv, 2), "RMSEcv =", round(RMSEcv, 2), "MAE = ", round(MAEt, 2)))
```

### Residual density 

In a well-fitting model, the residuals should follow a normal distribution.

```{r Residuals density}
MaxDens <- as.numeric(ceiling(max(SummaryModel$Residuals)))
MinDens <- as.numeric(floor(min(SummaryModel$Residuals)))

# The first plot
DensityPlot <- ggdensity((SummaryModel),
                          x = "Residuals",
                          size = 0.7,
                          fill = "Set", 
                          palette = c("#004AF5", "#F7B213")) +
  scale_x_continuous(limits = c(MinDens, MaxDens)) +
  scale_fill_manual(values = c("T" = "#004AF5", "V" = "#F7B213"), 
                    labels = c("Training Set", "Validation Set"))

DensityPlot <- ggpar(DensityPlot, legend.title = "", legend = "top", xlab = "", 
                      ylab = "Residual density %TDNA BAL", ggtheme = theme_bw())

DensityPlot <- DensityPlot + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", size = 1),
        panel.background = element_rect(fill = "#faf8ef"), 
        axis.title.y = element_text(size = 15), 
        legend.text = element_text(face = "bold", size = 10))

# Save Residual density plot to PNG
ggsave("docs/figures/ResDens.png", plot = DensityPlot, width = 1500, height = 1500, units = "px", dpi = 300)
```

![](docs/figures/ResDens.png){width=60%}
